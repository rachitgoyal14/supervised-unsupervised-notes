# Loss Functions - Overview

## ğŸ“š Contents

1. [[01. Loss Functions Concept|Loss Functions Concept]]
2. [[02. Mean Squared Error|Mean Squared Error]]
3. [[03. Root Mean Squared Error|Root Mean Squared Error]]
4. [[04. Mean Absolute Error|Mean Absolute Error]]
5. [[05. Square Function|Square Function]]
6. [[06. Assumptions of Linear Regression|Assumptions of Linear Regression]]

## ğŸ¯ Learning Objectives

- Understand what loss functions are
- Learn different types of error metrics
- Know when to use each metric

## ğŸ”— Related Sections

- [[03. Linear Regression Basics/00. Overview|Linear Regression Basics]]
- [[05. Gradient Descent/00. Overview|Gradient Descent]]

## ğŸ“ Resources

- Lectures: 10-12
- Notebooks: `../../linear-regression/`

Loss functions are the heart of machine learning optimizationâ€”they quantify how wrong our predictions are and guide the learning process. This section explores different loss functions (MSE, MAE), explains why we square errors, and covers the critical assumptions underlying linear regression. Understanding loss functions is essential for choosing the right metric for your problem and debugging model performance.
