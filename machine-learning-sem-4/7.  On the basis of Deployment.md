
> *How does a model continue learning after deployment?*

**Parent Note:** [[1. Types of Machine Learning]]

---

## Classification Based on Deployment

Machine learning models can be classified based on **how they handle new data** during and after deployment:

1. **Batch Learning** (Offline Learning)
2. **Online Learning** (Incremental Learning)
3. **Out-of-Core Learning**

---

## Standard ML Pipeline

```mermaid
graph LR
    PROBLEM[Problem Statement] --> TRAIN[Train Model<br/>Training Data]
    TRAIN --> TEST[Test Model<br/>Testing Data]
    TEST --> DEPLOY[Deploy<br/>Hugging Face, AWS, etc.]
    
    style PROBLEM fill:#9C27B0,color:#fff
    style TRAIN fill:#4CAF50,color:#fff
    style TEST fill:#FF9800,color:#fff
    style DEPLOY fill:#2196F3,color:#fff
```

---

## 1. Batch Learning (Offline Learning)

**Definition:** Train the model with the **entire dataset at once**, then deploy. Model remains **static** after deployment.

**Analogy:** *Like printing a textbook - once published, it doesn't update until the next edition.*

### The Process

```mermaid
graph TD
    DATA1[Complete Data] --> MODEL1[Train Model<br/>Offline]
    MODEL1 --> TEST1[Test]
    TEST1 --> DEPLOY1[Deploy]
    DEPLOY1 --> STATIC[Static Model<br/>No updates]
    
    WAIT[Wait: Week/Month] --> NEWDATA[New Data + Old Data]
    NEWDATA --> MODEL2[Retrain Model<br/>Offline]
    MODEL2 --> TEST2[Test]
    TEST2 --> REDEPLOY[Redeploy]
    REDEPLOY --> WAIT
    
    style DATA1 fill:#2196F3,color:#fff
    style STATIC fill:#F44336,color:#fff
    style NEWDATA fill:#FF9800,color:#fff
```

### Characteristics

- **Training:** Offline (on local system/server)
- **Data:** Entire dataset at once
- **Updates:** Periodic retraining required
- **Model State:** Static between updates
- **Evolution:** Not possible without retraining

### Problem: Static Model

**Example:** Netflix Recommendation System

```mermaid
graph TD
    TRAIN[Model trained on<br/>1000 shows] --> DEPLOY[Deploy]
    DEPLOY --> NEW[100 new movies<br/>added to Netflix]
    NEW --> INVISIBLE[New content NOT<br/>in recommendations]
    INVISIBLE --> RETRAIN[Must retrain<br/>model offline]
    
    style INVISIBLE fill:#F44336,color:#fff
```

**Issue:** New movies won't appear in recommendations until model is retrained with updated data.

### The Retraining Cycle

```mermaid
graph LR
    DEPLOY[Deployed Model] --> COLLECT[Collect New Data<br/>1 week/month]
    COLLECT --> MERGE[Old Data + New Data]
    MERGE --> RETRAIN[Retrain Offline]
    RETRAIN --> TEST[Test]
    TEST --> REDEPLOY[Redeploy]
    REDEPLOY --> DEPLOY
    
    style DEPLOY fill:#2196F3,color:#fff
    style RETRAIN fill:#FF9800,color:#fff
```

### When to Use

- Data is **not volatile** (changes slowly)
- Updates can happen periodically
- Examples: House price prediction, annual sales forecasting

### Pros & Cons

| Pros | Cons |
|------|------|
| Simple to implement | Model becomes outdated |
| Stable predictions | Cannot adapt to new patterns |
| Controlled updates | Requires periodic retraining |
| | Manual intervention needed |

---

## 2. Online Learning (Incremental Learning)

**Definition:** Model **continues learning** after deployment. New data is fed incrementally to update the model in real-time.

**Analogy:** *Like Wikipedia - constantly updated as new information becomes available.*

### The Process

```mermaid
graph TD
    PROBLEM[Problem Statement] --> TRAIN[Train Model<br/>Initial Training Data]
    TRAIN --> TEST1[Test]
    TEST1 --> ERROR[Error Analysis]
    ERROR --> TEST2[Retest]
    TEST2 --> DEPLOY[Deploy on Server]
    
    DEPLOY --> ONLINE[Model Online]
    ONLINE --> NEWDATA[New Data Arrives]
    NEWDATA --> LEARN[Learn Incrementally<br/>On Server]
    LEARN --> PREDICT[Continue Predictions]
    PREDICT --> NEWDATA
    
    style PROBLEM fill:#9C27B0,color:#fff
    style DEPLOY fill:#2196F3,color:#fff
    style LEARN fill:#4CAF50,color:#fff
```

### Characteristics

- **Training:** Online (on deployment server)
- **Data:** Incremental, continuous stream
- **Updates:** Real-time, automatic
- **Model State:** Continuously evolving
- **Evolution:** Happens automatically

### Key Difference

**Batch Learning:**
- Model taken **offline** for retraining
- Old data + New data merged
- Retrain completely
- Redeploy

**Online Learning:**
- Model stays **online** (never offline)
- New data fed directly to deployed model
- Learning happens on the server
- Predictions and learning happen simultaneously

### When to Use

- Data is **volatile** (changes frequently)
- Real-time adaptation needed
- Examples: Stock trading, social media feeds, recommendation systems

### Pros & Cons

| Pros | Cons |
|------|------|
| Real-time adaptation | Complex to implement |
| No downtime | Risk of learning bad patterns |
| Evolves with data | Requires monitoring |
| Automatic updates | Higher computational cost |

---

## 3. Out-of-Core Learning

**Definition:** Divide complete data into **chunks**, train model incrementally on each chunk. Combines aspects of batch and online learning.

**Analogy:** *Like eating a large pizza slice by slice instead of all at once.*

### The Problem with Complete Data

- Memory limitations
- Long training times
- Computational constraints
- Difficult to manage large datasets

### The Solution: Chunking

```mermaid
graph TD
    DATA[Complete Dataset] --> SPLIT[Split into Chunks]
    SPLIT --> C1[Chunk 1]
    SPLIT --> C2[Chunk 2]
    SPLIT --> C3[Chunk 3]
    SPLIT --> C4[Chunk N]
    
    C1 --> TRAIN1[Train on Chunk 1]
    TRAIN1 --> C2
    C2 --> TRAIN2[Update with Chunk 2]
    TRAIN2 --> C3
    C3 --> TRAIN3[Update with Chunk 3]
    TRAIN3 --> C4
    C4 --> TRAINN[Update with Chunk N]
    
    TRAINN --> TEST[Test]
    TEST --> ERROR[Error Analysis]
    ERROR --> DEPLOY[Deploy]
    DEPLOY --> ONLINE[Continue as Online Learning]
    
    style DATA fill:#2196F3,color:#fff
    style SPLIT fill:#FF9800,color:#fff
    style ONLINE fill:#4CAF50,color:#fff
```

### Characteristics

- **Training:** Incremental chunks (offline initially)
- **Data:** Divided into manageable pieces
- **Updates:** After deployment, follows online learning
- **Model State:** Evolves with each chunk
- **Complexity:** Higher than batch or online alone

### When to Use

- Dataset too large for memory
- Limited computational resources
- Need incremental learning with large data
- Examples: Training on terabytes of data, big data applications

### Pros & Cons

| Pros | Cons |
|------|------|
| Handles massive datasets | More complex implementation |
| Memory efficient | Risk of order-dependent learning |
| Scalable | Requires careful chunk management |
| | Model trained on multiple instances |

---

## Comparison Table

| Aspect | Batch Learning | Online Learning | Out-of-Core Learning |
|--------|----------------|-----------------|---------------------|
| **Training Location** | Offline (local system) | Online (deployment server) | Offline chunks → Online |
| **Data Handling** | Complete data at once | Incremental stream | Chunks, then stream |
| **Model Updates** | Periodic (manual) | Continuous (automatic) | Chunked → Continuous |
| **Downtime** | Yes (during retraining) | No | Initially yes, then no |
| **Complexity** | Low | Medium | High |
| **Memory Usage** | High | Low-Medium | Low |
| **Adaptability** | Low (static) | High (evolving) | Medium-High |
| **Risk Level** | Low | Medium | High |

---

## Real-World Examples

| Use Case | Batch Learning | Online Learning | Out-of-Core Learning |
|----------|----------------|-----------------|---------------------|
| **Example** | House price prediction | Stock trading algorithm | Training GPT on internet data |
| **Data Pattern** | Yearly updates | Real-time prices | Massive text corpus |
| **Update Frequency** | Monthly/Yearly | Every transaction | Chunks → Real-time |
| **Why This Approach?** | Prices stable, periodic updates OK | Prices volatile, need instant adaptation | Too much data for memory, then needs updates |

### Detailed Examples

**Batch Learning - House Price Prediction:**
- Train on last year's housing data
- Deploy model
- Use for 6 months
- Retrain with new 6 months data
- Redeploy

**Online Learning - Stock Trading:**
- Initial training on historical data (offline)
- Deploy to server
- Each new trade updates the model
- Model adapts to market changes in real-time
- Never goes offline

**Out-of-Core Learning - Language Model:**
- 100 TB of internet text data
- Split into 1000 chunks of 100 GB each
- Train on Chunk 1
- Update with Chunk 2
- Continue through all chunks
- Deploy and switch to online learning

---

## Key Insight: First Training

**Important:** The **first time a model is trained** is **always offline** (batch learning).

```mermaid
graph LR
    FIRST[First Training<br/>Always Offline] --> CHOICE{Deployment Strategy?}
    CHOICE -->|Static Model| BATCH[Batch Learning<br/>Periodic retraining]
    CHOICE -->|Evolving Model| ONLINE[Online Learning<br/>Continuous updates]
    CHOICE -->|Large Data| OUTCORE[Out-of-Core<br/>Then online]
    
    style FIRST fill:#9C27B0,color:#fff
    style BATCH fill:#4CAF50,color:#fff
    style ONLINE fill:#2196F3,color:#fff
    style OUTCORE fill:#FF9800,color:#fff
```

After initial training, you choose:
- **Batch:** Keep offline, retrain periodically
- **Online:** Deploy and continue learning on server
- **Out-of-Core:** Train in chunks, then deploy for online learning

---

## Quick Decision Guide

**Choose Batch Learning when:**
- Data changes slowly
- Periodic updates are acceptable
- Stability is more important than adaptability

**Choose Online Learning when:**
- Data is highly dynamic
- Real-time adaptation is critical
- Model must evolve continuously

**Choose Out-of-Core Learning when:**
- Dataset is too large for memory
- Need incremental training initially
- Plan to switch to online learning after deployment

---

## Related Notes

- [[0. Machine Learning Terms]]
- [[1. Types of Machine Learning]]

---

#batch-learning #online-learning #incremental-learning #model-deployment #mlops