
> *Think of machine learning like different teaching methods: some students need step-by-step guidance (supervised), others discover patterns themselves (unsupervised), while some learn by trying and getting feedback (reinforcement).*

---

## Overview

Machine learning can be categorized by **how much supervision** the algorithm needs during training:

```mermaid
graph TB
    ML[Machine Learning] --> SL[Supervised Learning]
    ML --> UL[Unsupervised Learning]
    ML --> SSL[Semi-Supervised Learning]
    ML --> SELF[Self-Supervised Learning]
    ML --> RL[Reinforcement Learning]
    
    SL --> SL_DESC["Learning with a teacher<br/>Labeled data provided"]
    UL --> UL_DESC["Self-discovery learning<br/>Find patterns yourself"]
    SSL --> SSL_DESC["Mixed approach<br/>Few labels + lots of data"]
    SELF --> SELF_DESC["Create your own homework<br/>Generate labels from data"]
    RL --> RL_DESC["Trial and error<br/>Learn from rewards/penalties"]
    
    style ML fill:#9C27B0,color:#fff
    style SL fill:#4CAF50,color:#fff
    style UL fill:#2196F3,color:#fff
    style SSL fill:#FF9800,color:#fff
    style SELF fill:#00BCD4,color:#fff
    style RL fill:#F44336,color:#fff
```

---

## 1. [[2. Supervised Machine Learning|Supervised Machine Learning]]

**Analogy:** *Like learning math with an answer key - you see the problem AND the solution.*

- **Data:** Input features + Output labels
- **Goal:** Learn the mapping from inputs to outputs
- **Types:** [[2. Supervised Machine Learning#Regression|Regression]], [[2. Supervised Machine Learning#Classification|Classification]]

**Example Dataset:**
| IQ  | CGPA | Placement |
| --- | ---- | --------- |
| 85  | 8.9  | Yes       |
| 90  | 8.0  | Yes       |
| 75  | 6.0  | No        |

---

## 2. [[3. Unsupervised Machine Learning|Unsupervised Machine Learning]]

**Analogy:** *Like organizing your closet without labels - you group similar items (colors, types) naturally.*

- **Data:** Only input features (no labels)
- **Goal:** Discover hidden patterns or structure

### Types of Unsupervised Learning

```mermaid
graph TB
    UL[Unsupervised Learning<br/>Unlabeled Data] --> VIZ[1. Visualization<br/>See patterns visually]
    UL --> CLUST[2. Clustering<br/>Group similar items]
    UL --> DIM[3. Dimensionality Reduction<br/>Feature extraction]
    UL --> ANOM[4. Anomaly Detection<br/>Find outliers]
    UL --> ASSOC[5. Association Rules<br/>Find relationships]
    
    VIZ --> VIZ_EX[matplotlib, seaborn<br/>PowerBI, Tableau]
    CLUST --> CLUST_EX[K-Means Clustering<br/>Hierarchical Clustering]
    DIM --> DIM_EX[Feature Reduction<br/>PCA, t-SNE]
    ANOM --> ANOM_EX[Outliers & Novelty<br/>Fraud Detection]
    ASSOC --> ASSOC_EX[Market Basket Analysis<br/>Recommendation Systems]
    
    style UL fill:#2196F3,color:#fff
    style VIZ fill:#9C27B0,color:#fff
    style CLUST fill:#4CAF50,color:#fff
    style DIM fill:#FF9800,color:#fff
    style ANOM fill:#F44336,color:#fff
    style ASSOC fill:#00BCD4,color:#fff
```

**Examples:**
- Customer segmentation (clustering)
- Fraud detection (anomaly detection)
- "Customers who bought X also bought Y" (association rules)

---

## 3. [[4. Semi-Supervised Machine Learning|Semi-Supervised Machine Learning]]

**Analogy:** *Like learning from a few textbook examples, then practicing with unlabeled problems.*

- **Data:** Small amount of labeled + Large amount of unlabeled
- **Use Case:** Labeling data is expensive/time-consuming
- **Example:** You have 100 labeled medical images but 10,000 unlabeled ones

---

## 4. Self-Supervised Learning

**Analogy:** *Like learning a language by predicting the next word in a sentence - you create your own exercises from raw text.*

- **Data:** Unlabeled data that creates its own labels
- **Examples:** 
  - Predict next word in sentence
  - Predict masked portions of images
  - Predict image rotation angle

---

## 5. Reinforcement Learning

**Analogy:** *Like training a dog - reward good behavior (sit = treat), penalize bad behavior (bark = no treat).*

- **Components:** Agent, Environment, Actions, Rewards/Penalties
- **Goal:** Maximize cumulative reward
- **Examples:** Game AI, robotics, self-driving cars

```mermaid
graph LR
    A[Agent] -->|Takes Action| E[Environment]
    E -->|Returns State + Reward| A
    
    style A fill:#F44336,color:#fff
    style E fill:#4CAF50,color:#fff
```

---

## Quick Comparison

| Type | Supervision | Use Case |
|------|-------------|----------|
| **Supervised** | Full labels | Prediction with known outcomes |
| **Unsupervised** | No labels | Pattern discovery |
| **Semi-Supervised** | Few labels | Limited labeled data |
| **Self-Supervised** | Auto-generated | Learn from structure |
| **Reinforcement** | Rewards/Penalties | Sequential decision-making |

---

## Related Notes

- [[0. Machine Learning Terms]]
- [[2. Supervised Machine Learning]] - Detailed breakdown of regression and classification
- [[3. Unsupervised Machine Learning]] - Detailed breakdown of clustering, dimensionality reduction, and more
- [[4. Semi-Supervised Machine Learning]]
- [[Deep Learning vs Machine Learning]]

---

#machine-learning #ai #data-science