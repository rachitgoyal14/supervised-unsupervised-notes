
How does the flowchart of training a machine learning model look like?

we have the problem statement first

then we have the model being trained on the training dataaset and then testing using testing dataset

and then we deploy it on hugging face


now what is batch learning?
its basically training the model with the entire data at once
there are a few pros and cons in this:
1. evolution is not possible since the model is being trained with the entire data at once
take an example of a netflix recommendation model but its trained on only the specific number of shows 
the new movies being added to the netflix as time passes are not visible to the user as recommendation as the model is ont trained on it
the model will be **static**

any model we design is why we update it at regular intervals

data ----> model -----> test ------> deploy

if there is fluctuating data the following approach is now used but it can be used in netflix, house price prediuction where data changes after some time

we can build a cycle after a week or a month and

then

data is not volatile in batch learning

new data + old data -------> model --------> test ------> deploy

build this inot a cyclic mermaid diagram


if i want the model to evolve over time, i need to implement batch learning
and this entire process is offline

the model does not learn on the deployment server
the model learns on the system locally
this is called batch learning

### Online Learning

data ---> model ---> test ---> deployment

the above is what the classic pipeline looks like
but we make a few changes and this is what we get

					test --> error analysis --> deployment

problem statement ---> model (using training data ) ---> test ----> error analysis ---> test ---> deployment

turn this into a cycle at error anlysis

this is `incremental learning`

in online learning, our model is never taken offline

the model is fed the new data on the online server deploymnent itself

in the previous case we had to take the model offline and merge the old data wth new data

whereas, learning as well as predictoin both happens on the server



draw a table for differentitaion between the two




#### Out of core Learning

batch learning ----> complete data
incremental learning -----> complete data


there are many things that can go wrong while handling with the entire data
out of core learning is a new approach where we divide the data into chunks and then train the model and hence we overcome the whole set of issues we have had with batch and incremental learing




complete data ----> show chunks being diviided -----> model being trained ----> rest process is same as online learning and hence complete the flowchart


this particular appraoch is risky and is relatively complicated



